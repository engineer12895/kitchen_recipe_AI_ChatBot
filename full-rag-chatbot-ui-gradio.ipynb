{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10477706,"sourceType":"datasetVersion","datasetId":6487786}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -qU langchain_community pypdf langchain-groq sentence_transformers faiss-gpu langgraph pydantic gradio","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T16:10:37.502195Z","iopub.execute_input":"2025-01-16T16:10:37.502486Z","iopub.status.idle":"2025-01-16T16:11:00.032782Z","shell.execute_reply.started":"2025-01-16T16:10:37.502463Z","shell.execute_reply":"2025-01-16T16:11:00.031972Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.7/139.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.4/431.4 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.4/321.4 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.6/109.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# LIBRARY\nfrom langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom langchain_community.embeddings import HuggingFaceBgeEmbeddings\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain.schema.runnable import RunnablePassthrough\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import MessagesPlaceholder\nfrom langchain.chains import create_history_aware_retriever\n\nfrom langchain.chains import create_retrieval_chain\nfrom langchain.chains.combine_documents import create_stuff_documents_chain\nfrom typing import List\nfrom operator import itemgetter\nfrom langchain_groq import ChatGroq\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_core.documents import Document\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-16T16:11:00.034193Z","iopub.execute_input":"2025-01-16T16:11:00.034511Z","iopub.status.idle":"2025-01-16T16:11:01.201615Z","shell.execute_reply.started":"2025-01-16T16:11:00.034480Z","shell.execute_reply":"2025-01-16T16:11:01.200997Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"os.environ['LANGCHAIN_TRACING_V2'] = 'true'\nos.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\nos.environ['LANGCHAIN_PROJECT'] = 'advanced-rag'\nos.environ['LANGCHAIN_API_KEY'] = \"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\"\nos.environ['GROQ_API_KEY'] = \"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\"\nos.environ['TAVILY_API_KEY'] = \"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\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T16:11:01.202807Z","iopub.execute_input":"2025-01-16T16:11:01.203128Z","iopub.status.idle":"2025-01-16T16:11:01.206796Z","shell.execute_reply.started":"2025-01-16T16:11:01.203107Z","shell.execute_reply":"2025-01-16T16:11:01.206062Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# UPLOAD THE DOCUMENTS\ndocuments = PyPDFLoader('/kaggle/input/cooking-dataset/cooking_book.pdf')\ndocuments = documents.load() ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T16:11:01.208275Z","iopub.execute_input":"2025-01-16T16:11:01.208571Z","iopub.status.idle":"2025-01-16T16:11:01.810653Z","shell.execute_reply.started":"2025-01-16T16:11:01.208544Z","shell.execute_reply":"2025-01-16T16:11:01.810001Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# SPLIT THE DOCUMENTS INTO CHUNK\ntxt_spliter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=150,length_function=len)\nsplits = txt_spliter.split_documents(documents)\nprint(f\"split the documents into {len(splits)} chunks\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T16:11:01.811339Z","iopub.execute_input":"2025-01-16T16:11:01.811656Z","iopub.status.idle":"2025-01-16T16:11:01.819111Z","shell.execute_reply.started":"2025-01-16T16:11:01.811636Z","shell.execute_reply":"2025-01-16T16:11:01.818112Z"}},"outputs":[{"name":"stdout","text":"split the documents into 128 chunks\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"#Create embedding\nmodel_name = 'BAAI/bge-small-en'\nmodel_kwargs = {\"device\": \"cuda\"}\nencode_kwargs = {\"normalize_embeddings\": True}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T16:11:01.820139Z","iopub.execute_input":"2025-01-16T16:11:01.820442Z","iopub.status.idle":"2025-01-16T16:11:01.837724Z","shell.execute_reply.started":"2025-01-16T16:11:01.820406Z","shell.execute_reply":"2025-01-16T16:11:01.836965Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"HF_embedding = HuggingFaceBgeEmbeddings(\n    model_name=model_name,\n    model_kwargs=model_kwargs,\n    encode_kwargs=encode_kwargs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T16:11:01.838560Z","iopub.execute_input":"2025-01-16T16:11:01.838845Z","iopub.status.idle":"2025-01-16T16:11:28.585893Z","shell.execute_reply.started":"2025-01-16T16:11:01.838824Z","shell.execute_reply":"2025-01-16T16:11:28.585177Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-7-801c86d419aa>:1: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n  HF_embedding = HuggingFaceBgeEmbeddings(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3702296d8fd4222b7124a0fbcb60670"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b240eade85c4ed0b6f757146c3207a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/90.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"766e35189af54380b09ceb2e2d781756"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4d50fbdd53a44a9935195469eec8eef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0824b9ace4bf4066a48dd74bf60c4575"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e83b80f2d1814551abfdfaaa0c5e6f66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1e23093862e407f9d32eec09e2ede81"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d14c9f1531ee4271a5ea5b887a1e87cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ec73fe4c65347e1b2cb7a413978629f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0029d454c3a44ae0a3234eae8a6193c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ea49e1d7d1a4f129c323d236f094ed6"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"#Vector store \nvectorstore = FAISS.from_documents(documents=splits, embedding=HF_embedding)\nretriever = vectorstore.as_retriever()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T16:11:28.587866Z","iopub.execute_input":"2025-01-16T16:11:28.588451Z","iopub.status.idle":"2025-01-16T16:11:29.635447Z","shell.execute_reply.started":"2025-01-16T16:11:28.588428Z","shell.execute_reply":"2025-01-16T16:11:29.634483Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def docs2str(documents):\n    return \"\\n\\n\".join(doc.page_content for doc in documents)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T16:11:29.636545Z","iopub.execute_input":"2025-01-16T16:11:29.636780Z","iopub.status.idle":"2025-01-16T16:11:29.640696Z","shell.execute_reply.started":"2025-01-16T16:11:29.636738Z","shell.execute_reply":"2025-01-16T16:11:29.639823Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# RAG\ntemplate = \"\"\"Answer the following question based on this context:\n{context}\nQuestion: {question}\n\"\"\"\n\nprompt = ChatPromptTemplate.from_template(template)\n\nllm = ChatGroq(temperature=0)\n\nfinal_rag_chain = ({\"context\": retriever | docs2str, \"question\": RunnablePassthrough()} \n                   | prompt\n                   | llm\n                   | StrOutputParser()\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T16:11:29.641379Z","iopub.execute_input":"2025-01-16T16:11:29.641617Z","iopub.status.idle":"2025-01-16T16:11:29.929042Z","shell.execute_reply.started":"2025-01-16T16:11:29.641597Z","shell.execute_reply":"2025-01-16T16:11:29.928184Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"question = \"how to cook Haleem?\"\nresponse = final_rag_chain.invoke(question)\nprint(f\"Question: {question}\")\nprint(f\"Answer: {response}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T16:11:29.930024Z","iopub.execute_input":"2025-01-16T16:11:29.930365Z","iopub.status.idle":"2025-01-16T16:11:30.708125Z","shell.execute_reply.started":"2025-01-16T16:11:29.930332Z","shell.execute_reply":"2025-01-16T16:11:30.707251Z"}},"outputs":[{"name":"stdout","text":"Question: how to cook Haleem?\nAnswer: To cook Haleem, follow this recipe:\n\n1. Soak rice, wheat, and dals (channa dal, mash dal, masoor dal) overnight.\n2. Mix haldi (turmeric), chilli powder, salt, onions, ginger paste, and 2 glasses of water with beef and cook till beef is tender.\n3. Fry the beef in 50 ml of oil. Remove beef pieces from curry.\n4. In the same oil, fry onions until golden brown. Add garam masala powder and curry masala to the fried onions.\n5. Blend the soaked rice, wheat, and dals into a smooth paste.\n6. Add the paste to the fried onions and stir. Add the beef pieces, remaining water, and cook until the water dries.\n7. For the filling, mix boiled eggs, coriander leaves, mint leaves, green chilies, and chat masala.\n8. Form the mixture into kababs and shallow fry until crisp and golden brown.\n9. Serve hot with chutney.\n\nNote: The recipe seems to have a mix of two different dishes - Haleem and Kebabs. The Haleem is a stew-like dish made with meat, lentils, and spices, while the kebabs are made with the ground meat and egg filling. You can choose to make either or both of them based on your preference.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"**---------------------------------------------------------------------------The more advance RAG System---------------------------------------------------------------------------------**","metadata":{}},{"cell_type":"code","source":"#\ncontextualize_q_system_prompt = \"\"\"\nGiven a chat history and the latest user question\nwhich might reference context in the chat history,\nformulate a standalone question which can be understood\nwithout the chat history. Do NOT answer the question,\njust reformulate it if needed and otherwise return it as is.\n\"\"\"\n\ncontextualize_q_prompt = ChatPromptTemplate.from_messages(\n    [\n        (\"system\", contextualize_q_system_prompt),\n        MessagesPlaceholder(\"chat_history\"),\n        (\"human\", \"{input}\"),\n    ]\n)\n\ncontextualize_chain = contextualize_q_prompt | llm | StrOutputParser()\nprint(contextualize_chain.invoke({\"input\": \"How to cook Haleem?\", \"chat_history\": []}))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T16:11:30.708979Z","iopub.execute_input":"2025-01-16T16:11:30.709188Z","iopub.status.idle":"2025-01-16T16:11:30.874844Z","shell.execute_reply.started":"2025-01-16T16:11:30.709169Z","shell.execute_reply":"2025-01-16T16:11:30.874136Z"}},"outputs":[{"name":"stdout","text":"You're asking for instructions on how to prepare Haleem. Here's the standalone question: \"What are the steps to cook Haleem?\"\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"history_aware_retriever = create_history_aware_retriever(\n    llm, retriever, contextualize_q_prompt\n)\n\nqa_prompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"You are a helpful AI assistant. Use the following context to answer the user's question.\"),\n    (\"system\", \"Context: {context}\"),\n    MessagesPlaceholder(variable_name=\"chat_history\"),\n    (\"human\", \"{input}\")\n])\n\nquestion_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\nrag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T16:11:30.875741Z","iopub.execute_input":"2025-01-16T16:11:30.876067Z","iopub.status.idle":"2025-01-16T16:11:30.883568Z","shell.execute_reply.started":"2025-01-16T16:11:30.876034Z","shell.execute_reply":"2025-01-16T16:11:30.882670Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"from langchain_core.messages import HumanMessage, AIMessage\n\nchat_history = []\nquestion1 = \"Ingradient for cooking Haleem?\"\nanswer1 = rag_chain.invoke({\"input\": question1, \"chat_history\": chat_history})['answer']\nchat_history.extend([\n    HumanMessage(content=question1),\n    AIMessage(content=answer1)\n])\n\nprint(f\"Human: {question1}\")\nprint(f\"AI: {answer1}\\n\")\n\nquestion2 = \"how to cook Haleem?\"\nanswer2 = rag_chain.invoke({\"input\": question2, \"chat_history\": chat_history})['answer']\nchat_history.extend([\n    HumanMessage(content=question2),\n    AIMessage(content=answer2)\n])\n\nprint(f\"Human: {question2}\")\nprint(f\"AI: {answer2}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T16:11:30.884236Z","iopub.execute_input":"2025-01-16T16:11:30.884452Z","iopub.status.idle":"2025-01-16T16:11:32.577838Z","shell.execute_reply.started":"2025-01-16T16:11:30.884433Z","shell.execute_reply":"2025-01-16T16:11:32.577116Z"}},"outputs":[{"name":"stdout","text":"Human: Ingradient for cooking Haleem?\nAI: The ingredients for cooking Haleem are:\n1 kg boneless beef\n2 tablespoons ginger garlic paste\n3 medium onions\n2 tablespoons chilli powder\n1 teaspoon haldi (turmeric)\n300 ml oil\n2 tablespoons salt\n2 tablespoons garam masala powder\nhalf cup channa dal (split chickpeas)\nhalf cup mash dal (split green gram)\nhalf cup masoor dal (red lentils)\nhalf cup rice\n1 cup wheat\nFor the filling:\n4 boiled eggs, finely chopped\n1 cup coriander leaves, finely chopped\n1 cup mint leaves, finely chopped\n2 or 3 green chilies, finely chopped\n1 teaspoon chat masala\nFor frying:\n1/4 cup besan (gram flour)\n2 eggs\nAdditionally, for the initial soaking:\nhaldi, chilli, salt, onions, ginger paste, and 2 glasses water\nFor cooking the meat:\nblack pepper, cloves, bari elaichi (black cardamom), jeera (cumin), cinnamon, kari patta (curry leaves), and 3-4 glasses of water.\n\nNote: Some of the ingredients are repeated in the method section, I have included them for clarity.\n\nHuman: how to cook Haleem?\nAI: Here's a step-by-step guide to cook Haleem:\n\n1. Soak the rice, wheat, and dals (channa dal, mash dal, masoor dal) overnight.\n2. Mix haldi (turmeric), chilli powder, salt, onions, ginger paste, and 2 glasses of water with the beef and cook till the beef is tender.\n3. Fry the beef pieces in 50 ml of oil and remove them from the curry.\n4. In the same oil, fry the soaked dals, rice, and wheat until they turn golden brown.\n5. Add the beef curry, garam masala powder, and 3-4 glasses of water to the fried dals, rice, and wheat.\n6. Cook the mixture on low flame for 2-3 hours, stirring occasionally.\n7. In a separate pan, fry besan (gram flour) in 2 tbsp of oil until it turns golden brown.\n8. Beat 2 eggs and mix it with the fried besan.\n9. Add this mixture to the haleem and cook for another 15-20 minutes.\n10. For the filling, mix boiled eggs, coriander leaves, mint leaves, green chilies, and chat masala.\n11. Serve the haleem hot, garnished with the filling, grated ginger, coriander leaves, and slit green chilies.\n\nNote: You can adjust the amount of water and cooking time as per your desired consistency and tenderness of the haleem.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"**-------------------------------------Gradio----------------------------------**","metadata":{}},{"cell_type":"code","source":"import gradio as gr\n\ndef generate_answer(messages, state):\n    user_message = messages[-1]\n    chat_history = [{'role': 'user', 'content': msg} for msg in messages]\n    input_dict = {\"input\": user_message, \"chat_history\": chat_history}\n    response = rag_chain.invoke(input_dict)\n    return response['answer']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T16:11:32.583218Z","iopub.execute_input":"2025-01-16T16:11:32.583427Z","iopub.status.idle":"2025-01-16T16:11:34.749036Z","shell.execute_reply.started":"2025-01-16T16:11:32.583402Z","shell.execute_reply":"2025-01-16T16:11:34.748133Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"import gradio as gr\n\ngr.ChatInterface(\n    fn=generate_answer, \n    type=\"messages\",\n    textbox=gr.Textbox(placeholder=\"Type your cooking-related question here...\", container=False, scale=7),\n    title=\"Smart Kitchen Assistant\",\n    chatbot=gr.Chatbot(height=300, type=\"messages\"),\n    description=\"Welcome to the Smart Kitchen Assistant! Powered by Retrieval-Augmented Generation (RAG), \"\n        \"this tool provides detailed cooking instructions. Simply ask about any recipe, and get \"\n        \"a list of required ingredients followed by step-by-step instructions to prepare the dish.\",\n).launch()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T16:24:36.431949Z","iopub.execute_input":"2025-01-16T16:24:36.432307Z","iopub.status.idle":"2025-01-16T16:24:37.230257Z","shell.execute_reply.started":"2025-01-16T16:24:36.432284Z","shell.execute_reply":"2025-01-16T16:24:37.229161Z"}},"outputs":[{"name":"stdout","text":"* Running on local URL:  http://127.0.0.1:7865\nKaggle notebooks require sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n\n* Running on public URL: https://91d1cb445dfae77742.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://91d1cb445dfae77742.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}